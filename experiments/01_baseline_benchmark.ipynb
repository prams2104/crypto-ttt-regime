{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ee50a85d",
      "metadata": {},
      "source": [
        "# Experiment 01: Baseline & TTT Benchmark\n",
        "\n",
        "**Research Question** (from README):\n",
        "> Can self-supervised Test-Time Training adapt a vision-based volatility classifier to non-stationary crypto market regimes without access to ground-truth labels during inference?\n",
        "\n",
        "This notebook reproduces the baseline benchmark and compares three evaluation modes:\n",
        "1. **Baseline** - fixed model, no adaptation\n",
        "2. **TTT (standard)** - adapt per sample, reset encoder\n",
        "3. **TTT (online)** - adapt sequentially, keep encoder state\n",
        "\n",
        "**Requirements**: `data/raw/btcusdt_1h.parquet` must exist. Run from project root."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2328c3fd",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# Ensure project root is on path (works from experiments/ or project root)\n",
        "cwd = os.getcwd()\n",
        "PROJECT_ROOT = os.path.dirname(cwd) if os.path.basename(cwd) == \"experiments\" else cwd\n",
        "if PROJECT_ROOT not in sys.path:\n",
        "    sys.path.insert(0, PROJECT_ROOT)\n",
        "os.chdir(PROJECT_ROOT)\n",
        "print(f\"Working directory: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Preparation\n",
        "\n",
        "Creates `data/processed/dataset.pt` from raw OHLCV parquet. Skips if already exists."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9236ced",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from src.dataset import prepare_dataset\n",
        "\n",
        "pt_path = Path(\"data/processed/dataset.pt\")\n",
        "if not pt_path.exists():\n",
        "    prepare_dataset(\n",
        "        parquet_path=\"data/raw/btcusdt_1h.parquet\",\n",
        "        output_dir=\"data/processed\",\n",
        "        train_end=\"2022-12-31\",\n",
        "        val_end=\"2023-12-31\",\n",
        "        seed=42,\n",
        "    )\n",
        "    print(\"Dataset created.\")\n",
        "else:\n",
        "    print(f\"Dataset exists: {pt_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Training\n",
        "\n",
        "**Baseline (no aux)**: `--aux_task none`\n",
        "\n",
        "**Joint (mask aux)**: `--aux_task mask --lambda_aux 1.0` — required for TTT."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Joint training with temporal masking aux task (for TTT)\n",
        "!python -m src.train --parquet data/raw/btcusdt_1h.parquet \\\n",
        "  --train_end 2022-12-31 --val_end 2023-12-31 \\\n",
        "  --epochs 30 --aux_task mask --lambda_aux 1.0 \\\n",
        "  --checkpoint_dir checkpoints/joint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: Baseline (no aux) for comparison\n",
        "# !python -m src.train --parquet data/raw/btcusdt_1h.parquet \\\n",
        "#   --train_end 2022-12-31 --val_end 2023-12-31 \\\n",
        "#   --epochs 30 --aux_task none --checkpoint_dir checkpoints/baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Evaluation\n",
        "\n",
        "Runs baseline, TTT (standard), and TTT (online). Uses `--threshold 0.35` to improve recall on minority (high-vol) class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m src.eval --checkpoint checkpoints/joint/best.pt \\\n",
        "  --ttt_steps 10 --ttt_lr 0.5 --ttt_optimizer adam \\\n",
        "  --entropy_adaptive --threshold 0.35"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Results Summary\n",
        "\n",
        "| Mode | Accuracy | F1 | ECE | Brier | IC |\n",
        "|------|----------|-----|-----|-------|-----|\n",
        "| Baseline | - | - | - | - | - |\n",
        "| TTT (standard) | - | - | - | - | - |\n",
        "| TTT (online) | - | - | - | - | - |\n",
        "\n",
        "*Copy values from eval output above. Example from a typical run:*\n",
        "\n",
        "| Mode | Accuracy | F1 | ECE | Brier | IC |\n",
        "|------|----------|-----|-----|-------|-----|\n",
        "| Baseline | 0.76 | 0.08 | 0.06 | 0.17 | 0.09 |\n",
        "| TTT (standard) | 0.47 | 0.32 | 0.15 | 0.19 | 0.06 |\n",
        "| TTT (online) | 0.34 | 0.35 | 0.20 | 0.21 | -0.03 |\n",
        "\n",
        "**Interpretation**: TTT increases F1 (better recall on high-vol) at the cost of accuracy and calibration. Check `TTT aux_loss: initial=... → final=...` to confirm adaptation is occurring."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbb3c745",
      "metadata": {},
      "source": [
        "## 6. Visualization: Prediction Changes Before/After TTT\n",
        "\n",
        "Per proposal: \"Visualization of prediction changes before and after test-time adaptation will be included to illustrate how the model responds to regime shifts.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9aac769",
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from src.dataset import CryptoRegimeDataset\n",
        "from src.models import TTTModel\n",
        "from src.ttt_learner import TTTAdaptor\n",
        "from src.utils import get_device\n",
        "\n",
        "# Config\n",
        "CHECKPOINT = \"checkpoints/joint/best.pt\"\n",
        "N_SAMPLES = 200  # subsample for faster viz\n",
        "TTT_STEPS, TTT_LR = 10, 0.5\n",
        "\n",
        "device = get_device()\n",
        "ckpt = torch.load(CHECKPOINT, map_location=device, weights_only=False)\n",
        "train_args = ckpt.get(\"args\", {})\n",
        "aux_task = train_args.get(\"aux_task\", \"mask\")\n",
        "mask_mode = train_args.get(\"mask_mode\", \"random_slices\")\n",
        "num_groups = train_args.get(\"num_groups\", 8)\n",
        "\n",
        "model = TTTModel(num_classes=2, aux_task=aux_task, num_groups=num_groups).to(device)\n",
        "model.load_state_dict(ckpt[\"model_state_dict\"])\n",
        "\n",
        "dataset = CryptoRegimeDataset(\"data/processed\")\n",
        "_, _, test_ds = dataset.get_splits()\n",
        "loader = DataLoader(test_ds, batch_size=1, shuffle=False)\n",
        "\n",
        "adaptor = TTTAdaptor(model=model, base_lr=TTT_LR, ttt_steps=TTT_STEPS, mask_mode=mask_mode,\n",
        "                     ttt_optimizer=\"adam\", entropy_adaptive=True, device=device)\n",
        "\n",
        "probs_baseline, probs_ttt, labels = [], [], []\n",
        "for i, (images, lbl, _) in enumerate(loader):\n",
        "    if i >= N_SAMPLES:\n",
        "        break\n",
        "    images = images.to(device)\n",
        "    with torch.no_grad():\n",
        "        logits_b = model.forward_main(images)\n",
        "        p_b = torch.softmax(logits_b, dim=-1)[:, 1].item()\n",
        "    logits_t, _ = adaptor.adapt_and_predict(images)\n",
        "    p_t = torch.softmax(logits_t, dim=-1)[:, 1].item()\n",
        "    probs_baseline.append(p_b)\n",
        "    probs_ttt.append(p_t)\n",
        "    labels.append(lbl.item())\n",
        "\n",
        "probs_baseline = np.array(probs_baseline)\n",
        "probs_ttt = np.array(probs_ttt)\n",
        "labels = np.array(labels)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
        "\n",
        "# Left: Baseline vs TTT scatter (red=high_vol, blue=low_vol)\n",
        "axes[0].scatter(probs_baseline[labels==0], probs_ttt[labels==0], c=\"blue\", alpha=0.6, label=\"low_vol\")\n",
        "axes[0].scatter(probs_baseline[labels==1], probs_ttt[labels==1], c=\"red\", alpha=0.6, label=\"high_vol\")\n",
        "axes[0].plot([0, 1], [0, 1], \"k--\", lw=1)\n",
        "axes[0].set_xlabel(\"P(high_vol) Baseline\")\n",
        "axes[0].set_ylabel(\"P(high_vol) After TTT\")\n",
        "axes[0].set_title(\"Prediction Change Before/After TTT\")\n",
        "axes[0].legend()\n",
        "\n",
        "# Right: Histogram of delta\n",
        "delta = probs_ttt - probs_baseline\n",
        "axes[1].hist(delta[labels == 0], bins=20, alpha=0.6, label=\"low_vol\", color=\"blue\")\n",
        "axes[1].hist(delta[labels == 1], bins=20, alpha=0.6, label=\"high_vol\", color=\"red\")\n",
        "axes[1].axvline(0, color=\"k\", ls=\"--\")\n",
        "axes[1].set_xlabel(\"Delta P(high_vol) = TTT - Baseline\")\n",
        "axes[1].set_ylabel(\"Count\")\n",
        "axes[1].set_title(\"Distribution of Prediction Shifts\")\n",
        "axes[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e853c648",
      "metadata": {},
      "source": [
        "## 7. Future Experiments\n",
        "\n",
        "Add new cells with different configs and record results:\n",
        "\n",
        "- `--ttt_steps 5` or `20`\n",
        "- `--ttt_lr 0.1` or `0.3`\n",
        "- `--ttt_optimizer sgd`\n",
        "- `--aux_task rotation` (train with rotation aux)\n",
        "- `--mask_mode rightmost` (extrapolation instead of interpolation)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
